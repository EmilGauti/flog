{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilGauti/flog/blob/master/flog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KdrmHJd0iwwS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VbBcFhUcDac7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.1.   (klára/laga features) reikna auðkenni á minni tímabútum og skeyta því saman í lengri auðkennavigur \n",
        "\n",
        "1.2.   prófa fleiri flokkara (svm, tré), tuna parametra, prófa með basic test-train á öllum gögnum\n",
        "\n",
        "1.3.   Fá út accuracy, sens og spec (ruglingsfylki) (kannski matthews líka?)\n",
        "\n",
        "\n",
        "\n",
        "2.1.   Klára patient specific skriftu (kasta út acc, spec og sens á alla og svo meðaltal)\n",
        "\n",
        "2.2.   Keyra hana með besta (eða öllum) flokkaranum\n",
        "\n",
        "\n",
        "\n",
        "3.1.   Fourier myndadót eins og í grein úr pósti\n",
        "\n",
        "3.2.   Tauganet á það\n",
        "\n",
        "\n",
        "\n",
        "4.1   (Vega mikilvægi features ef við notum tré)"
      ]
    },
    {
      "metadata": {
        "id": "CdbNU5SI-1Lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#input: \n",
        "#filename: name of file to read from\n",
        "#shape: dimension of resulting array                   \n",
        "def read3DArrayFromFile(fileName,shape):                      \n",
        "    data = np.loadtxt(fileName, dtype = 'float32')\n",
        "    data = data.reshape(shape)\n",
        "    return(data)\n",
        "\n",
        "nrPatients = 24\n",
        "fs = 256 # Sampling rate\n",
        "nrChannels = 23\n",
        "seizureLength = 14 # seconds\n",
        "nrSeizures = 170\n",
        "fRange = 129\n",
        "M = 16\n",
        "fLowerLimit = 0.5\n",
        "fUpperLimit = 25\n",
        "dataShape = (nrSeizures,nrChannels,seizureLength*fs)\n",
        "\n",
        "# Read raw data\n",
        "seizureData = read3DArrayFromFile('seizureChunks14.txt',dataShape)\n",
        "nonSeizureData = read3DArrayFromFile('nonSeizureChunks14.txt',dataShape)\n",
        "allData = np.concatenate((seizureData,nonSeizureData),axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWoIzt6w7DXc",
        "colab_type": "code",
        "outputId": "68315156-e028-4ec0-bb0a-3f59301d4188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# FLOKKARARw\n",
        "\n",
        "tlength = 3.5 # calculate features for each time interval of tlength seconds (must divide seizureLength)\n",
        "\n",
        "[X,y] = create_data_matrix(allData, nrSeizures, nrChannels, fRange, fs, M, fLowerLimit, fUpperLimit, seizureLength, tlength, hjorth = True)\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "print('Logistic Regression classifier trained on data from pooled subjects')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "clf=LogisticRegression(max_iter  = 200)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy: \", clf.score(X_test, y_test))\n",
        "###############\n",
        "#\n",
        "#####################\n",
        "#Emil að bæta við classifierum\n",
        "#Setti líka þá classifiera sem voru hér\n",
        "#í meira compact format\n",
        "#####################\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "\n",
        "La = linear_model.Lasso()\n",
        "Et = ExtraTreesRegressor(n_jobs=-1, n_estimators=500)\n",
        "Rf = RandomForestRegressor(n_jobs=-1, n_estimators=500)\n",
        "Gbt = GradientBoostingRegressor()\n",
        "clf_ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3))#kannski má ekki vera max_depth>1\n",
        "clf_tree = DecisionTreeClassifier(random_state=0)      \n",
        "clf_svm = svm.SVC()\n",
        "clf_LR=LogisticRegression(max_iter  = 200)\n",
        "\n",
        "\n",
        "name = [La,Et,Rf,Gbt,clf_tree,clf_svm,clf_LR,clf_ada]\n",
        "names_s = ['La','Et','Rf','Gbt','clf_tree', 'clf_svm', 'clf_LR', 'clf_ada']\n",
        "for i in range(len(name)):\n",
        "    name[i].fit(X_train,y_train)\n",
        "    print(names_s[i]+' score:' , name[i].score(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (340, 368)\n",
            "y: (340,)\n",
            "Logistic Regression classifier trained on data from pooled subjects\n",
            "Accuracy:  0.7411764705882353\n",
            "SVM\n",
            "Accuracy:  0.4588235294117647\n",
            "Decision Tree\n",
            "Accuracy:  0.7176470588235294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qk4STVC7zQMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "######### CONFUSION MATRIX\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "cm = metrics.confusion_matrix(y_test,clf_ada.predict(X_test))\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(cm, cmap='cool')\n",
        "plt.title('Confusion matrix Adaboost Classifier')\n",
        "plt.xlabel('Raunverulegt gildi')\n",
        "plt.ylabel('Metið gildi')\n",
        "plt.xticks([0,1])\n",
        "plt.yticks([0,1])\n",
        "plt.colorbar()\n",
        "n = cm.shape[0]\n",
        "p = cm.shape[1]\n",
        "blabb = ['True negative','False positive','False negative','True positive']\n",
        "ind=0\n",
        "for i in range(n):\n",
        "    for j in range(p):        \n",
        "        plt.annotate(str(cm[i,j]),xy=(i,j), \n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "        plt.annotate(blabb[ind],xy=(i,j+0.1), horizontalalignment='center'\n",
        "                     , verticalalignment='center')\n",
        "        ind=ind+1\n",
        "sens = cm[1,1]/(cm[1,1] + cm[1,0])\n",
        "spec = cm[0,0]/(cm[0,0] + cm[0,1])\n",
        "\n",
        "print('Model sensitivity:', sens)\n",
        "print('Model specificity:', spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6h1xOy6iE3bA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FEATURES\n",
        "\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "# Hjorth parameters (time domain)\n",
        "# https://en.wikipedia.org/wiki/Hjorth_parameters\n",
        "def hjorth_mobility(x):\n",
        "    num = np.var(np.diff(x))\n",
        "    den = np.var(x)\n",
        "    if den > 0:\n",
        "        return np.sqrt(num / den)\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def hjorth_parameters(x):\n",
        "    activity=np.var(x)\n",
        "    mobility=hjorth_mobility(x)\n",
        "    if mobility > 0:\n",
        "        complexity=hjorth_mobility(np.diff(x)) / mobility\n",
        "    else:\n",
        "        complexity=0.0\n",
        "    return np.array([activity, mobility, complexity])\n",
        "\n",
        "#Calculates power spectral density for an eeg segment\n",
        "#inputs: \n",
        "#signalMat: signal matrix for chunk\n",
        "#fs: sampling density\n",
        "#n: number of channels\n",
        "#outputs: \n",
        "#f: frequency\n",
        "#Pwelch: power spectral density calculated by Welch's method\n",
        "def psd(signalMat,fs,n,fRange):\n",
        "    Pwelch = np.zeros((n,fRange))\n",
        "    for i in range(n):\n",
        "        F,Pwelch[i,:] = signal.welch(signalMat[i,:],fs,scaling = 'spectrum')\n",
        "    return(F,Pwelch)\n",
        "\n",
        "# Absolute band power\n",
        "# Combined power in M frequency bands\n",
        "def absolute_power(f, PSD,M,l,h):\n",
        "    length = (h-l)/M\n",
        "    power = []\n",
        "    k = l\n",
        "    for i in range(M):\n",
        "        power.append(sum(PSD[np.where((f > k) & (f <= k+length))]))\n",
        "        k +=length\n",
        "    return(power)\n",
        "    \n",
        "#Relative power of delta, theta, alpha \n",
        "#and beta waves for a single channel\n",
        "def relative_power(f,PSD,M,l,h):\n",
        "    absPow = absolute_power(f,PSD,M,l,h)\n",
        "    tot = sum(PSD)\n",
        "    if tot > 0.0:\n",
        "        return(absPow/tot)\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "# Calculate relative band power for the whole data set\n",
        "# THINK: Might want to do the same for absolute power\n",
        "def relative_power_all(allData, nrSeizures, nrChannels, fRange, fs, M, fLowerLimit, fUpperLimit):\n",
        "    dataPSD = np.zeros((nrSeizures*2,nrChannels,fRange))\n",
        "    for i in range(nrSeizures*2):\n",
        "        [F,dataPSD[i,:,:]] = psd(allData[i,:,:],fs,nrChannels,fRange)\n",
        "\n",
        "    dataRelPower = np.zeros((nrSeizures*2,nrChannels,M))\n",
        "    for i in range(nrSeizures*2):\n",
        "        for j in range(nrChannels):\n",
        "            dataRelPower[i,j,:] = relative_power(F,dataPSD[i,j,:],M,fLowerLimit,fUpperLimit)\n",
        "    return(dataRelPower)\n",
        "    \n",
        "def create_data_matrix(allData, nrSeizures, nrChannels, fRange, fs, M, fLowerLimit, fUpperLimit, seizureLength, tlength, hjorth = True):\n",
        "    \n",
        "    assert seizureLength % tlength == 0, 'tlength does not divide seizureLength'\n",
        "    numt = int(seizureLength / tlength)\n",
        "    dataRelPower = np.zeros((nrSeizures*2, nrChannels, M, numt))\n",
        "    k = 0\n",
        "    for i in range(numt):\n",
        "        tData = allData[:,:,k:int(k+tlength*fs)]\n",
        "        dataRelPower[:,:,:,i] = relative_power_all(tData, nrSeizures, nrChannels, fRange, fs, M, fLowerLimit, fUpperLimit)\n",
        "        k += int(tlength*fs)\n",
        "        \n",
        "    dataRelPowerFlat = np.zeros((nrSeizures*2,nrChannels*M*numt))\n",
        "    for i in range(nrSeizures*2):\n",
        "        dataRelPowerFlat[i,:] = dataRelPower[i,:,:,:].flatten()\n",
        "        \n",
        "    if hjorth:\n",
        "        hjopar = np.zeros((nrSeizures*2,nrChannels,3,numt))\n",
        "        for i in range(nrSeizures*2):\n",
        "            for j in range(nrChannels):\n",
        "                k = 0\n",
        "                for t in range(numt):\n",
        "                    tData = allData[:,:,k:int(k+tlength*fs)]\n",
        "                    hjopar[i,j,:,t] = hjorth_parameters(tData[i,j,:])\n",
        "                    k += int(tlength*fs)\n",
        "                    \n",
        "        hjoparflat = np.zeros((nrSeizures*2,nrChannels*3*numt))\n",
        "        for i in range(nrSeizures*2):\n",
        "            hjoparflat[i,:] = hjopar[i,:,:,:].flatten()\n",
        "        dataRelPowerFlat = np.c_[dataRelPowerFlat, hjoparflat]\n",
        "    \n",
        "    \n",
        "    X = dataRelPowerFlat\n",
        "    y = np.concatenate((np.repeat(1,nrSeizures),np.repeat(0,nrSeizures)))\n",
        "        \n",
        "    return(X,y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCnrupwEHIno",
        "colab_type": "code",
        "outputId": "be8db5fc-ed5f-497f-b477-261af21afcdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2254
        }
      },
      "cell_type": "code",
      "source": [
        "# PATIENT SPECIFIC\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# Patient-specific classifier\n",
        "\n",
        "# Pre: Execute main.py\n",
        "\n",
        "import ast\n",
        "\n",
        "def fixIndex(i):\n",
        "    if i < 10:\n",
        "        i = '0'+str(i)\n",
        "    return(str(i))\n",
        "\n",
        "nonSeizureFileNames = open('nonSeizureFileNames.txt', 'r')\n",
        "nonSeizureFileNames = nonSeizureFileNames.read().split('\\n')\n",
        "\n",
        "with open('seizureDict.txt', 'r') as f:\n",
        "    s = f.read()\n",
        "    seizureDict = ast.literal_eval(s)\n",
        "\n",
        "patientResults = np.zeros((nrPatients+1, 6))\n",
        "\n",
        "for testPatient in range(1,nrPatients+1):\n",
        "    #gets index of seizures that belong to testPatient (+nrSeizures since seizure chunks are first in allData)\n",
        "    prefix = 'chb'+fixIndex(testPatient)\n",
        "    nonSeizIndices = [i+nrSeizures for i, s in enumerate(nonSeizureFileNames) if s.startswith(prefix)]\n",
        "    testPatientKeys = [i for i in seizureDict.keys() if i.startswith(prefix)]\n",
        "    k = 0\n",
        "    seizIndices = []\n",
        "    for key in seizureDict:    \n",
        "        for i in range(len(seizureDict[key])):\n",
        "            if key in testPatientKeys:\n",
        "                seizIndices.append(k)\n",
        "            k = k+1\n",
        "\n",
        "    patientResults[testPatient-1,:3] = [testPatient, len(seizIndices), len(nonSeizIndices)]\n",
        "    \n",
        "    X_test = np.concatenate((X[seizIndices,:],X[nonSeizIndices,:]),axis = 0)\n",
        "    y_test = np.concatenate((y[seizIndices],y[nonSeizIndices]))\n",
        "    X_train = np.delete(X, nonSeizIndices, axis=0)\n",
        "    X_train = np.delete(X_train, seizIndices, axis=0)\n",
        "    y_train = np.delete(y,nonSeizIndices)\n",
        "    y_train = np.delete(y_train,seizIndices)\n",
        "    # THINK: Collect statistics on seizure/nonseizure\n",
        "    \n",
        "    # Classify individual patient\n",
        "    # Insert code here ...\n",
        "    clf=LogisticRegression(max_iter = 200)\n",
        "    clf.fit(X_train, y_train)\n",
        "    patientResults[testPatient-1, 3] = clf.score(X_test, y_test)\n",
        "\n",
        "patientResults[-1, 3] = np.mean(patientResults[:,3])\n",
        "\n",
        "dash = '-' * 120\n",
        "print(dash)\n",
        "print('{:^15s}{:^15s}{:^15s}{:^15s}{:^15s}{:^15s}'.format('Patient', '# Seizures', '# non Seizures', 'Accuracy', 'Sensitivity', 'Specificity'))\n",
        "print(dash)\n",
        "for i in range(patientResults.shape[0]-1):\n",
        "    print('{:^15d}{:^15d}{:^15d}{:^15f}{:^15f}{:^15f}'.format(int(patientResults[i,0]), int(patientResults[i,1]), int(patientResults[i,2]), patientResults[i,3], patientResults[i,4], patientResults[i,5]))\n",
        "print(dash)\n",
        "print('{:^15s}{:^15s}{:^15s}{:^15f}{:^15f}{:^15f}'.format('MEAN', '', '', patientResults[-1, 3], patientResults[-1, 4], patientResults[-1, 5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patient  1 n_seizures= 7 n_nonseizures= 11\n",
            "Train: (322, 437) Test: (18, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9444444444444444\n",
            "Patient  2 n_seizures= 2 n_nonseizures= 15\n",
            "Train: (323, 437) Test: (17, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7647058823529411\n",
            "Patient  3 n_seizures= 7 n_nonseizures= 5\n",
            "Train: (328, 437) Test: (12, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5833333333333334\n",
            "Patient  4 n_seizures= 4 n_nonseizures= 14\n",
            "Train: (322, 437) Test: (18, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6111111111111112\n",
            "Patient  5 n_seizures= 4 n_nonseizures= 15\n",
            "Train: (321, 437) Test: (19, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7894736842105263\n",
            "Patient  6 n_seizures= 10 n_nonseizures= 3\n",
            "Train: (327, 437) Test: (13, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.38461538461538464\n",
            "Patient  7 n_seizures= 3 n_nonseizures= 4\n",
            "Train: (333, 437) Test: (7, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5714285714285714\n",
            "Patient  8 n_seizures= 5 n_nonseizures= 5\n",
            "Train: (330, 437) Test: (10, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9\n",
            "Patient  9 n_seizures= 4 n_nonseizures= 4\n",
            "Train: (332, 437) Test: (8, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  1.0\n",
            "Patient  10 n_seizures= 7 n_nonseizures= 9\n",
            "Train: (324, 437) Test: (16, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8125\n",
            "Patient  11 n_seizures= 3 n_nonseizures= 13\n",
            "Train: (324, 437) Test: (16, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.75\n",
            "Patient  12 n_seizures= 27 n_nonseizures= 4\n",
            "Train: (309, 437) Test: (31, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.2903225806451613\n",
            "Patient  13 n_seizures= 10 n_nonseizures= 1\n",
            "Train: (329, 437) Test: (11, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6363636363636364\n",
            "Patient  14 n_seizures= 8 n_nonseizures= 6\n",
            "Train: (326, 437) Test: (14, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5\n",
            "Patient  15 n_seizures= 19 n_nonseizures= 3\n",
            "Train: (318, 437) Test: (22, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.13636363636363635\n",
            "Patient  16 n_seizures= 1 n_nonseizures= 2\n",
            "Train: (337, 437) Test: (3, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6666666666666666\n",
            "Patient  17 n_seizures= 3 n_nonseizures= 6\n",
            "Train: (331, 437) Test: (9, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7777777777777778\n",
            "Patient  18 n_seizures= 6 n_nonseizures= 11\n",
            "Train: (323, 437) Test: (17, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5882352941176471\n",
            "Patient  19 n_seizures= 3 n_nonseizures= 10\n",
            "Train: (327, 437) Test: (13, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7692307692307693\n",
            "Patient  20 n_seizures= 7 n_nonseizures= 8\n",
            "Train: (325, 437) Test: (15, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5333333333333333\n",
            "Patient  21 n_seizures= 4 n_nonseizures= 9\n",
            "Train: (327, 437) Test: (13, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6153846153846154\n",
            "Patient  22 n_seizures= 3 n_nonseizures= 8\n",
            "Train: (329, 437) Test: (11, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8181818181818182\n",
            "Patient  23 n_seizures= 7 n_nonseizures= 1\n",
            "Train: (332, 437) Test: (8, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.875\n",
            "Patient  24 n_seizures= 16 n_nonseizures= 3\n",
            "Train: (321, 437) Test: (19, 437)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8421052631578947\n",
            "Mean accuracy: 0.6733574084466362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-598126432902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy Quantiles:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'quantile'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SWQ8X1Bji8dq",
        "colab_type": "code",
        "outputId": "50acd674-2fac-45cf-9d53-55ee4f487a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "print('Mean accuracy:', np.quantile(scores, 0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-03eae546441d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'quantiles'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "M4d3sUU0pkZt",
        "colab_type": "code",
        "outputId": "80257c88-2217-4108-9cee-c31bf1c36218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "cell_type": "code",
      "source": [
        "###Fourier/wavelet boio\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#input: \n",
        "#filename: name of file to read from\n",
        "#shape: dimension of resulting array                   \n",
        "def read3DArrayFromFile(fileName,shape):                      \n",
        "    data = np.loadtxt(fileName, dtype = 'float32')\n",
        "    data = data.reshape(shape)\n",
        "    return(data)\n",
        "\n",
        "nrPatients = 24\n",
        "fs = 256 # Sampling rate\n",
        "nrChannels = 23\n",
        "seizureLength = 14 # seconds\n",
        "nrSeizures = 170\n",
        "fRange = 129\n",
        "M = 16\n",
        "fLowerLimit = 0.5\n",
        "fUpperLimit = 25\n",
        "dataShape = (nrSeizures,nrChannels,seizureLength*fs)\n",
        "\n",
        "# Read raw data\n",
        "seizureData = read3DArrayFromFile('seizureChunks14.txt',dataShape)\n",
        "nonSeizureData = read3DArrayFromFile('nonSeizureChunks14.txt',dataShape)\n",
        "allData = np.concatenate((seizureData,nonSeizureData),axis = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-722da5bfa438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Read raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mseizureData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread3DArrayFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seizureChunks14.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mnonSeizureData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread3DArrayFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nonSeizureChunks14.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mallData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseizureData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonSeizureData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-722da5bfa438>\u001b[0m in \u001b[0;36mread3DArrayFromFile\u001b[0;34m(fileName, shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#shape: dimension of resulting array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread3DArrayFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# converting the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(chunk_size)\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0mline_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 raise ValueError(\"Wrong number of columns at line %d\"\n\u001b[0;32m-> 1016\u001b[0;31m                                  % line_num)\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of columns at line 681"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BuDFARIPsCXp",
        "colab_type": "code",
        "outputId": "43576fb2-7a58-492d-9932-95e793825db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2152
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from tensorflow.python.keras.layers import Dense#, Activation\n",
        "from tensorflow.python.keras.layers import Flatten\n",
        "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D\n",
        "from tensorflow.python.keras.optimizers import Adadelta\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "n,m,p = allData.shape\n",
        "fr = np.zeros((n,m,p))\n",
        "for i in range(n):\n",
        "  for j in range(m):\n",
        "    fr[i,j,:] = np.fft.fft(allData[i,j,:])\n",
        "frFlat = np.zeros((n,m*p))\n",
        "for i in range(n):\n",
        "  frFlat[i,:] = fr[i,:,:].flatten()\n",
        "# Calculate EEG features\n",
        "X = fr\n",
        "print(\"X:\", X.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "print(X_train.shape)\n",
        "num_classes=1\n",
        "num_epochs = 20\n",
        "batch_sizeA=300\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# set up early stopping\n",
        "es = EarlyStopping(monitor='val_acc',\n",
        "                   min_delta=0,\n",
        "                   patience=2,\n",
        "                   verbose=0, mode='auto')\n",
        "\n",
        "modelA = Sequential([ \n",
        "    Conv1D(32, kernel_size=10, activation='relu', padding = \"same\", input_shape = input_shape),\n",
        "    Conv1D(32, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    MaxPooling1D(pool_size=5),\n",
        "    Conv1D(64, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    Conv1D(64, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    MaxPooling1D(pool_size=5),\n",
        "    Conv1D(128, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    Conv1D(128, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    Conv1D(128, kernel_size=10, activation='relu', padding = \"same\"),\n",
        "    MaxPooling1D(pool_size=5),\n",
        "    Flatten(),\n",
        "    Dense(100, activation = 'relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation = 'sigmoid') ])\n",
        "\n",
        "modelA.summary()\n",
        "\n",
        "modelA.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "historyA=modelA.fit(X_train, y_train,\n",
        "                  batch_size=batch_sizeA,\n",
        "                  epochs=num_epochs,\n",
        "                 # callbacks = [es],\n",
        "                  verbose=1,\n",
        "                  validation_data=(X_test, y_test))\n",
        "scoreA = modelA.evaluate(X_test, y_test, verbose=0)\n",
        "print('val loss:', scoreA[0])\n",
        "print('val accuracy:', scoreA[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X: (340, 23, 3584)\n",
            "y: (340,)\n",
            "(255, 23, 3584)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 4 for 'max_pooling1d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,4,1,64].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-c5d1b5128029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     Dense(1, activation = 'sigmoid') ])\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmodelA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         data_format=self.data_format)\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   4619\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4620\u001b[0m     x = nn.max_pool(\n\u001b[0;32m-> 4621\u001b[0;31m         x, pool_size, strides, padding=padding, data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   4622\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4623\u001b[0m     x = nn.avg_pool(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   2746\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2747\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2748\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   5135\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   5136\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5137\u001b[0;31m                    data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   5138\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3300\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1823\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 4 for 'max_pooling1d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,4,1,64]."
          ]
        }
      ]
    }
  ]
}